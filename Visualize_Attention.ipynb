{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dmc2gym\n",
    "import utils\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from curl_sac import RadSacAgent\n",
    "from torchvision import transforms\n",
    "\n",
    "# for visualization\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "gpu_index = 7\n",
    "data_aug = 'rotate'  # 'crop' 'no_aug' 'cutout' 'cutout_color' 'flip' 'rotate' 'color_jitter'\n",
    "\n",
    "agent_type = 'rad_sac'\n",
    "pre_step = 500000\n",
    "domain_name = 'walker'  # 'walker' 'cartpole' 'humanoid'\n",
    "task_name = 'walk' # 'walk' 'swingup' 'stand'\n",
    "root_dir = './results/'\n",
    "\n",
    "env_name = domain_name + '-' + task_name\n",
    "exp_name = env_name + '-im84-b128-s1234-pixel-' + data_aug\n",
    "model_dir = root_dir + exp_name + '/model/'\n",
    "\n",
    "encoder_type = 'pixel'\n",
    "pre_transform_image_size = 100\n",
    "image_size = 84\n",
    "action_repeat = 4\n",
    "frame_stack = 3\n",
    "hidden_dim = 1024\n",
    "discount = 0.99\n",
    "init_temperature = 0.1\n",
    "alpha_lr = 1e-4\n",
    "alpha_beta = 0.5\n",
    "actor_lr = 1e-3\n",
    "actor_beta = 0.9\n",
    "actor_log_std_min = -10\n",
    "actor_log_std_max = 2\n",
    "actor_update_freq = 2\n",
    "critic_lr = 1e-3\n",
    "critic_beta = 0.9\n",
    "critic_tau = 0.01\n",
    "critic_target_update_freq = 2\n",
    "encoder_feature_dim = 50\n",
    "encoder_lr = 1e-3\n",
    "encoder_tau = 0.05\n",
    "num_layers = 4\n",
    "num_filters = 32\n",
    "log_interval = 100\n",
    "detach_encoder = False\n",
    "curl_latent_dim = 128\n",
    "num_eval_episodes = 1\n",
    "\n",
    "if data_aug is not 'crop':\n",
    "    pre_transform_image_size = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_index)\n",
    "utils.set_seed_everywhere(seed)\n",
    "env = dmc2gym.make(    \n",
    "    domain_name=domain_name,\n",
    "    task_name=task_name,\n",
    "    seed=seed,\n",
    "    visualize_reward=False,\n",
    "    from_pixels=(encoder_type == 'pixel'),\n",
    "    height=pre_transform_image_size,\n",
    "    width=pre_transform_image_size,\n",
    "    frame_skip=action_repeat\n",
    ")\n",
    "env.seed(seed)\n",
    "\n",
    "# stack several consecutive frames together\n",
    "if encoder_type == 'pixel':\n",
    "    env = utils.FrameStack(env, k=frame_stack)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "action_shape = env.action_space.shape\n",
    "\n",
    "if encoder_type == 'pixel':\n",
    "    obs_shape = (3*frame_stack, image_size, image_size)\n",
    "    pre_aug_obs_shape = (3*frame_stack, pre_transform_image_size, pre_transform_image_size)\n",
    "else:\n",
    "    obs_shape = env.observation_space.shape\n",
    "    pre_aug_obs_shape = obs_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agent(obs_shape, action_shape, device):\n",
    "    return RadSacAgent(\n",
    "        obs_shape=obs_shape,\n",
    "        action_shape=action_shape,\n",
    "        device=device,\n",
    "        hidden_dim=hidden_dim,\n",
    "        discount=discount,\n",
    "        init_temperature=init_temperature,\n",
    "        alpha_lr=alpha_lr,\n",
    "        alpha_beta=alpha_beta,\n",
    "        actor_lr=actor_lr,\n",
    "        actor_beta=actor_beta,\n",
    "        actor_log_std_min=actor_log_std_min,\n",
    "        actor_log_std_max=actor_log_std_max,\n",
    "        actor_update_freq=actor_update_freq,\n",
    "        critic_lr=critic_lr,\n",
    "        critic_beta=critic_beta,\n",
    "        critic_tau=critic_tau,\n",
    "        critic_target_update_freq=critic_target_update_freq,\n",
    "        encoder_type=encoder_type,\n",
    "        encoder_feature_dim=encoder_feature_dim,\n",
    "        encoder_lr=encoder_lr,\n",
    "        encoder_tau=encoder_tau,\n",
    "        num_layers=num_layers,\n",
    "        num_filters=num_filters,\n",
    "        log_interval=log_interval,\n",
    "        detach_encoder=detach_encoder,\n",
    "        latent_dim=curl_latent_dim,\n",
    "        data_augs=data_aug,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = make_agent(\n",
    "    obs_shape=obs_shape,\n",
    "    action_shape=action_shape,\n",
    "    device=device,\n",
    ")\n",
    "agent.load(model_dir, pre_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_idx = 2\n",
    "all_ep_rewards = []\n",
    "start_time = time.time()\n",
    "for i in range(num_eval_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    obs_list = []\n",
    "    attention_list = []\n",
    "    while not done:\n",
    "        # center crop image\n",
    "        if encoder_type == 'pixel' and 'crop' in data_aug:\n",
    "            obs = utils.center_crop_image(obs, image_size)\n",
    "            \n",
    "        with utils.eval_mode(agent):\n",
    "            action, attention = agent.select_action_with_attention(obs / 255., attention_idx)\n",
    "        obs_list.append(obs.astype('int16'))\n",
    "        attention_list.append(attention)\n",
    "        \n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "    print('episode_reward: ' + str(episode_reward))\n",
    "    all_ep_rewards.append(episode_reward)\n",
    "\n",
    "mean_ep_reward = np.mean(all_ep_rewards)\n",
    "best_ep_reward = np.max(all_ep_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_index = 10\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(9.3, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "fig.subplots_adjust(left=0.03, right=0.97, hspace=0.3, wspace=0.05)\n",
    "count = 0\n",
    "start_index = show_index\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(obs_list[start_index][(count)*3:(count+1)*3,:,:].swapaxes(2,0).swapaxes(1,0))\n",
    "    count += 1\n",
    "    if count == 3:\n",
    "        start_index += 1\n",
    "        count = 0\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(9.3, 6),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "fig.subplots_adjust(left=0.03, right=0.97, hspace=0.3, wspace=0.05)\n",
    "count = show_index\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(attention_list[count])\n",
    "    count += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curl",
   "language": "python",
   "name": "curl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
